# This is the directory in your NFS host where all data will actually be stored
# keep this in mind when you declare your volumes
export_dir: /srv/swarm/docker/volumes

# This is a list of volumes you want the NFS host to expect
# Note that if you declare additional volumes in your compose stacks but do not instruct your NFS host here, the ssh+nfs magic won't work
docker_volumes:
  - zeek-logs
  - zeek-spool
  - suricata-logs
  - crowdsec-database
  - rita-database
  - threatintel-database
  - threatintel-logs
  - rita-logs
  - dvwa-logs
  - swag-logs

# name of unprivileged user in the NFS host that accepts incoming SSH tunnels
ssh_tunneling_user: tunneler

# port number through which docker hosts locally see the remote NFS server after SSH tunnel has been established
# keep this in mind when you declare your volumes
ssh_tunneling_local_port: 12345

# this is where some pretty cool behaviors emerge
# you can set target group from inventory, compose stack name from ./docker and tell ansible if you want that particular compose stack to be present or not
# this setup works fine for one sniffer, one analysis host and one vulnerable app for testing
requested_stacks:
  - { project_name: purpleids, stack_name: nsm, target: 'networkHosts', status: present }
  - { project_name: purpleids, stack_name: purpleids, target: 'analysisHosts', status: present }
  - { project_name: purpleids, stack_name: dvwa, target: 'analysisHosts', status: present }
